    <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
    <!-- original template from from url=(0035)http://www.cs.berkeley.edu/~barron/ -->
    <html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
    <meta name="viewport" content="width=800">
    <meta name="description" content="Xiaopeng Yan's Homepage">
    <meta name="keyword" content="严肖朋,Xiaopeng Yan,yanxp,yan xiaopeng">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?2b1caf4b32ddf30714eeb2bc14bb5ab7";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-109057479-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-109057479-1');
    </script>

    <style type="text/css">
      /* Color scheme stolen from Sergey Karayev */
      a {
        color: #1772d0;
        text-decoration:none;
      }
      a:focus, a:hover {
        color: #f09228;
        text-decoration:none;
      }
      body,td,th {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 15px
      }
      strong {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 15px;
      }
      heading {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 20px;
      }
      papertitle {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 15px;
        font-weight: 700
      }
      subtitle{
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 18px;
      }
      name {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 32px;
      }
      .fade {
        transition: opacity .2s ease-in-out;
        -moz-transition: opacity .2s ease-in-out;
        -webkit-transition: opacity .2s ease-in-out;
      }
    </style>

    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <!-- <link rel="icon" type="image/png" href="http://www.cs.berkeley.edu/~barron/seal_icon.png"> -->

    <title>Xiaopeng Yan</title>

    <link href="/img/css" rel="stylesheet" type="text/css">
    </head>
    <body>
      <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
        <tbody><tr>
          <td>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody><tr>
                <td width="68%" valign="middle">
                  <p align="center">
                    <name>Xiaopeng Yan</name>
                  </p><p align="">&nbsp;&nbsp;&nbsp;&nbsp;I am a master student in <a href="http://www.sysu-hcp.net/home/">Human Cyber Physical Intelligence Integration Lab</a> at the  <a href="http://www.sysu.edu.cn" > SUN YAT-SEN UNIVERSITY</a>, led by Professor <a href="http://www.linliang.net/">Liang Lin</a>. Now, I am majoring in computer science at <a href="http://sdcs.sysu.edu.cn/">School of Data and Computer Science </a> during M.S. I received a B.E. in automation at <a href="http://seit.sysu.edu.cn/">School of Electronics and Information Technology</a>. I was as an intern at <a href="https://www.sensetime.com/">SenseTime</a> from July,2018 to March,2019.
                </br>
                <p align="center">Email:yanxp3(at)mail2.sysu.edu.cn
                </br>
              </br>
              <a href="./files/cv.pdf">Download CV Here</a> </p>
            </p>
          </td>
          <td> <img src="./imgs/yanxp_pic.JPG" style="width: 200;"></td></tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td>
              <heading><b>Research</b></heading>
              <p>
                <subtitle><strong>Computer Vision</strong></subtitle>
              </br>object detection</br>
              video classification</br>
              generative adversarial network (GAN)
            </br>
            <subtitle><strong>Machine Learning</strong></subtitle>
          </br>self-supervised learning and deep active learning</br>
          weakly-supervised learning 
        </br>
      </p>
    </td>
    </tr>
    </tbody></table>
    <!--SECTION -->

    <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td>
          <heading>News</heading>
                     </td>
                </tr>
              </tbody></table> -->
              <!--SECTION -->

              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody><tr>
                  <td>
                    <heading><b>Publications</b></heading>
                  </td>
                </tr>
              </tbody></table>


              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                 <tr>


                  <td width="25%"><img src="./imgs/cvpr.png" alt="PontTuset" width="200" style="border-style: none">
                  </td><td width="75%" valign="top">
                  <p><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Towards_Human-Machine_Cooperation_CVPR_2018_paper.pdf">
                   <papertitle>Towards Human-Machine Cooperation:Self-supervised Sample Mining for Object Detection</papertitle></a>
                   <br>
                   Keze Wang,<strong>Xiaopeng Yan</strong>, Dongyu Zhang, Lei Zhang, Liang Lin
                   <br>
                   <em>IEEE Conference on Computer Vision and Pattern Recognition(<strong>CVPR</strong>)</em>, 2018 &nbsp; <br>
                   <a href="http://www.sysu-hcp.net/ssm/">Project</a> /
                   <a href="https://arxiv.org/pdf/1803.09867.pdf">PDF</a> /
                   <a href="https://github.com/yanxp/SSM">code</a> /
                   <a href="https://github.com/yanxp/SSM-Pytorch">pytorch-version</a>
                 </p><p></p>
                 <!-- <p>Though quite challenging, leveraging large-scale unlabeled or partially labeled images in a cost-effective way has increasingly attracted interests for its great importance to computer vision. To tackle this problem, many Active Learning (AL) methods have been developed. However,these methods mainly define their sample selection criteria within a single image context, ...
                 </br></br>
               </p> --><p></p>
               <p></p>
             </td>
          </tr>
                  
                  <td width="25%"><img src="./imgs/asm.png" alt="PontTuset" width="200" style="border-style: none">
                  </td><td width="75%" valign="top">
                  <p><a href="https://arxiv.org/pdf/1807.00147.pdf">
                   <papertitle>Cost-Effective Object Detection: Active Sample Mining with Switchable Selection Criteria</papertitle></a>
                   <br>
                   Keze Wang, Liang Lin, <strong>Xiaopeng Yan</strong>, Dongyu Zhang, Ziliang Chen, Lei Zhang
                   <br>
                   <em>IEEE Transactions on Neural Networks and Learning System (<strong>TNNLS</strong>)</em>, 2018 &nbsp; <br>
                   <a href="http://www.sysu-hcp.net/asm/">Project</a> /
                   <a href="https://arxiv.org/pdf/1807.00147.pdf">PDF</a> /
                   <a href="https://github.com/yanxp/ASM">code</a> /
                   <a href="https://github.com/yanxp/ASM-Pytorch">pytorch-version</a>
                 </p><p></p>
                 <!-- <p>Though quite challenging, the training of object detectors using large-scale unlabeled or partially labeled datasets has attracted increasing interests from researchers due to its fundamental importance for applications of neural networks and learning systems. To address this problem, many active learning (AL) methods have been proposed that employ upto-date detectors ...
                 </br></br>
               </p> --><p></p>
               <p></p>
             </td>
          </tr>
                  <!--Next paper should be listed in bottom -->
                  <td width="25%"><img src="./imgs/self-learning.jpg" alt="PontTuset" width="200" style="border-style: none">
                  </td><td width="75%" valign="top">
                  <p><a href="http://www.sysu-hcp.net/wp-content/uploads/2017/07/YanXiaoPeng-Thesis.pdf">
                   <papertitle>Self-Learning Framework for Visual Recognition</papertitle></a>
                   <br>
                   <em><strong>Excellent graduation thesis of SYSU</strong></em>, 2017 &nbsp; <br>
                   <a href="./files/YanXiaoPeng-Thesis.pdf">PDF</a> /
                   <a href="https://github.com/yanxp/self-learning-framwork">code</a>
                 </p><p></p>
                 <!-- <p>In the graduation paper a general self-learning framework is proposed. It is effective on semi-supervised object detection. The proposed framework proposes to train object detectors by faithfully recognizing high-confidence object proposals in a self-paced way, and discovering low-confidence ones for user annotation in a active learning way.
                 </br></br>
               </p> --><p></p>
               <p></p>
             </td>
           </tr>


           <!--SECTION -->

           <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td>
              <heading><b>Projects</b></heading>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody><tr>

              </td><td width="75%" valign="top">
              <p><a><papertitle>The Sixth Price of Meitu Short Video Real-time Classification Competition</a></br>
               <em>Guang Zhou</em>, 2018.8-2018.9  &nbsp; <br>
               <a href="https://github.com/yanxp/VideoNet.git">code</a> /
               <a href="https://challenge.ai.meitu.com/mtsvrc2018/introduction.html">mtsvrc2018</a>
             </p><p></p>
             <p>As a captain of three team, we get the sixth price in the competition using the strategy of using ffmpeg extract the key frame of video and bilinear operation with hard example mining and data distillation.
            </p><p></p>
            <p></p>
          </td>
        </tr>


              <!--Next paper should be listed in bottom -->
              <!-- <td width="25%"><img src="./imgs/team.jpg" alt="PaohiTeam" width="160" style="border-style: none"> -->
              </td><td width="75%" valign="top">
              <p><a href="./files/plans.ppt">
                   <papertitle>Running Hi</papertitle></a></br>
               Guoen Tao,<strong>Xiaopeng Yan</strong>,Hao Wang,Xin Zhang,Ziyun Zhang,Yongqiu,Yishun Zheng,Jingsen Chen<br>
               <em>Sun Yat-sen University & Guangzhou University</em>, 2014-2015 &nbsp; <br>
               <a href="./files/plans.ppt">PDF</a> /
               <a href="./imgs/award.jpg">Award</a> /
               <a href="https://github.com/yanxp/runninghi">code</a>
             </p><p></p>
             <p>This project aims to develop an App and a Websit to supply service for college students to run and social interaction.We got the first place in the south china division of Lenovo Group national students entrepreneurship competition.
            </p><p></p>
            <p></p>
          </td>
        </tr>
                    
              
                     <!--Next paper should be listed in bottom -->
              <!-- <td width="25%"><img src="./imgs/chinatelecom.jpg" alt="Chinatelecom" width="160" style="border-style: none"> -->
              </td><td width="75%" valign="top">
              <p><a><papertitle>As an intern in China Telecom</a></br>
               <em>Guang Zhou</em>, 2015.7-8  &nbsp; <br>
             </p><p></p>
             <p>During the internship, I almost used the big data paltform such as Hadoop and Spark to analysis the users' data. By analysising the users' all kinds of data, We maked a plan where to bulid a billboard on the freeway.
            </p><p></p>
            <p></p>
          </td>
        </tr>

                         <!--Next paper should be listed in bottom -->
              <!-- <td width="25%"><img src="./imgs/bigdata.jpeg" alt="BigData" width="160" style="border-style: none"> -->
              </td><td width="75%" valign="top">
              <p><a><papertitle>As a developer in the Lab for big data and communication in SYSU</a></br>
               <em>Guang Zhou</em>, 2014.8-2015.6  &nbsp; <br>
               <a href="https://github.com/yanxp/weibo">code of Weibo</a>,
               <a href="https://github.com/yanxp/bcd">code of LDA</a>
             </p><p></p>
             <p>During these time, I writed a crawler program to crawl the Weibo users' data by the user's location. And I also writed a Latent Dirichlet Allocation algorithm to analysis the users' data  
             in the form of HTML.
            </p><p></p>
            <p></p>
          </td>
        </tr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td>
              <br>
              <p align="center"><font size="3">
                copyright@2017-2019
              </p>
            </td>
          </tr>
        </tbody></table>
        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

        </script><script src="./img/ga.js" type="text/javascript"></script> <script type="text/javascript">
        try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
        } catch(err) {}

      </script>
    </td>
    </tr>
    </tbody></table>


    </body></html>
